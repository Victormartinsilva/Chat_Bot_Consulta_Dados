# üöÄ Guia de Instala√ß√£o do Ollama

## Passo 1: Instalar o Ollama

### Windows:
1. **Baixe o instalador:**
   - Acesse: https://ollama.ai/download
   - Baixe o instalador para Windows
   - Execute o arquivo `.exe` baixado

2. **Ou use o PowerShell:**
   ```powershell
   # Baixe usando winget (se dispon√≠vel)
   winget install Ollama.Ollama
   
   # Ou use o instalador direto
   # Baixe de: https://ollama.ai/download/windows
   ```

## Passo 2: Verificar Instala√ß√£o

Abra um novo terminal PowerShell e execute:

```powershell
ollama --version
```

Se aparecer a vers√£o, est√° instalado corretamente!

## Passo 3: Baixar um Modelo

Escolha um modelo (recomendamos `llama3.2` por ser r√°pido e eficiente):

```powershell
ollama pull llama3.2
```

**Outros modelos dispon√≠veis:**
- `llama3.2` - Recomendado (r√°pido e bom)
- `mistral` - Alternativa leve
- `codellama` - Focado em c√≥digo (maior, mas melhor para an√°lise de dados)

**Tempo estimado:** 5-15 minutos dependendo da sua internet

## Passo 4: Iniciar o Servidor Ollama

O Ollama precisa estar rodando para funcionar. Voc√™ tem duas op√ß√µes:

### Op√ß√£o A: Iniciar manualmente (recomendado para teste)
```powershell
ollama serve
```
**Deixe este terminal aberto!** O servidor precisa estar rodando.

### Op√ß√£o B: Executar como servi√ßo (Windows)
O Ollama geralmente inicia automaticamente como servi√ßo no Windows ap√≥s a instala√ß√£o.

**Verificar se est√° rodando:**
```powershell
# Teste se o servidor est√° respondendo
curl http://localhost:11434/api/tags
```

## Passo 5: Testar o Modelo

```powershell
ollama run llama3.2 "Ol√°, como voc√™ est√°?"
```

Se responder, est√° tudo funcionando! ‚úÖ

## Passo 6: Configurar o Chatbot

O arquivo `.env` j√° foi configurado com:
```env
LLM_PROVIDER=ollama
OLLAMA_MODEL=llama3.2
OLLAMA_BASE_URL=http://localhost:11434
```

## Passo 7: Instalar Depend√™ncias Python

```powershell
pip install langchain-community
```

Ou instale todas as depend√™ncias:
```powershell
pip install -r requirements.txt
```

## Passo 8: Reiniciar o Streamlit

1. Pare o Streamlit (Ctrl+C)
2. Inicie novamente:
```powershell
streamlit run app.py
```

## ‚úÖ Pronto!

Agora seu chatbot est√° usando Ollama 100% gratuito!

## üîß Solu√ß√£o de Problemas

### Erro: "Connection refused"
- Certifique-se de que o Ollama est√° rodando: `ollama serve`
- Verifique se a porta 11434 est√° livre

### Erro: "Model not found"
- Baixe o modelo: `ollama pull llama3.2`
- Verifique se o nome do modelo no `.env` est√° correto

### Ollama n√£o inicia
- Reinicie o computador ap√≥s a instala√ß√£o
- Verifique se h√° antiv√≠rus bloqueando
- Tente executar como administrador

## üìö Mais Informa√ß√µes

- Site oficial: https://ollama.ai/
- Documenta√ß√£o: https://github.com/ollama/ollama
- Modelos dispon√≠veis: https://ollama.ai/library

